"""
This snakefile reproduces analyses from:

Webster TH et al. 2018. Identifying, understanding, and correcting technical
biases on the sex chromosomes in next-generation sequencing data.

Requires:
	Python 3
	snakemake (python package)
	bwa
	bedtools
	samtools
	samblaster
	BBmap (rename.sh is part of this suite of tools)
	separate Anaconda directory with XYalign and its dependencies installed

Runs analyses on 2 datasets:
*Dataset1 contains fastq files from exome, low-coverage whole-genome, and
high-coverage whole-genome sequencing for one male (HG00512) and one female (HG00513)
from the 1000 genomes project

*Dataset2 contains bam files from high-coverage whole-genome sequencing for
24 individuals from the 1000 genomes project

2 Reference Genomes are required for analyses:
*hg19 for mapping dataset1

*human_g1k_v37_decoy.fasta from the Broad Institute's resource bundle is required
for dataset2 because this was the genome used to generate the bam files

Before running the snakefile, complete the top of this script with
paths to various reference genomes and directories
containing bam and fastq files.

See the README for more information about downloading files, setting up conda environments,
and using snakemake to run the snakefile.

"""
# Update configfile if not in same directory
configfile: "Webster_etal_2018_xyalign.config.json"

# Path to XYalign
# If installed and in PATH, then leave values as-is
xyalign_path = "xyalign"
plot_count_stats_path = "plot_count_stats"
plot_window_differences_path = "plot_window_differences"

# Name of anaconda XYalign environment (for running xyalign analysis rules)
# See: http://xyalign.readthedocs.io/en/latest/installation.html for more information
xyalign_anaconda_env =

# Path to hg19 reference (including filename). hg19_ref_prefix is everything in
# the path *except the suffix of the file name*.
# For example, if hg19_ref_path is "reference/hg19.fasta", then hg19_ref_prefix
# should be "reference/hg19" (i.e., excluding the final ".fasta")
hg19_ref_path =
hg19_ref_prefix =

# Path to 1000 genomes reference (including filename) used in to generate the
# 24 1000 genomes bam files.  See information at the top of this script for how
# to find and download this file.
# thousand_genomes_ref_prefix is everything in
# the path *except the suffix of the file name*.
# For example, if thousand_genomes_ref_path is "reference/human_g1k_v37_decoy.fasta", then
# thousand_genomes_ref_prefix should be "reference/human_g1k_v37_decoy" (i.e., excluding the final ".fasta")
thousand_genomes_ref_path =
thousand_genomes_ref_prefix =

# Path to fastq files (include ending "/").  This is assuming that all fastqs from a
# given species are in the same directory.
human_fastq_directory =

# Path to 1000 genomes bam files (the 24 individuals)
thousand_genomes_bam_directory =

# Path to hg19 reference mask (also located in the XYalign/Files/PARs directory)
hg19_reference_mask_path = "misc/hg19_PAR_Ymask_startEnd.bed"

# Paths to tools used in the pipeline. Update if in different location or
# under different name
rename_sh_path = "rename.sh"
bcftools_path = "bcftools"
bedtools_path = "bedtools"
bgzip_path = "bgzip"
bwa_path = "bwa"
samtools_path = "samtools"
samblaster_path = "samblaster"

human_list = [
	"HG00512_exome", "HG00512_lowcov", "HG00512_wgs",
	"HG00513_exome", "HG00513_lowcov", "HG00513_wgs"]

thousand_list = [
	"HG00096.wgs.ILLUMINA.bwa.GBR", "HG01879.wgs.ILLUMINA.bwa.ACB",
	"HG03052.wgs.ILLUMINA.bwa.MSL", "HG01051.wgs.ILLUMINA.bwa.PUR",
	"NA19625.wgs.ILLUMINA.bwa.ASW", "HG01583.wgs.ILLUMINA.bwa.PJL",
	"HG03742.wgs.ILLUMINA.bwa.ITU", "NA20502.wgs.ILLUMINA.bwa.TSI",
	"NA18525.wgs.ILLUMINA.bwa.CHB", "HG02922.wgs.ILLUMINA.bwa.ESN",
	"NA19648.wgs.ILLUMINA.bwa.MXL", "HG00419.wgs.ILLUMINA.bwa.CHS",
	"HG01112.wgs.ILLUMINA.bwa.CLM", "NA19017.wgs.ILLUMINA.bwa.LWK",
	"HG00268.wgs.ILLUMINA.bwa.FIN", "HG02568.wgs.ILLUMINA.bwa.GWD",
	"HG01500.wgs.ILLUMINA.bwa.IBS", "NA18939.wgs.ILLUMINA.bwa.JPT",
	"HG03642.wgs.ILLUMINA.bwa.STU", "HG03006.wgs.ILLUMINA.bwa.BEB",
	"HG00759.wgs.ILLUMINA.bwa.CDX", "NA20845.wgs.ILLUMINA.bwa.GIH",
	"HG01595.wgs.ILLUMINA.bwa.KHV", "HG01565.wgs.ILLUMINA.bwa.PEL"]

rule all:
	input:
		expand(
			"processed_bams/{sample}.hg19.mkdup.sorted.bam",
			sample=human_list),
		expand(
			"processed_bams/{sample}.hg19.mkdup.sorted.bam.bai",
			sample=human_list),
		expand(
			"xyalign_analyses/hg19/logfiles/{sample}_hg19_xyalign.log",
			sample=human_list),
		expand(
			"xyalign_analyses/thousand_genomes/logfiles/{sample}_1000genomes_xyalign.log",
			sample=thousand_list),
		expand(
			thousand_genomes_bam_directory + "{sample}.high_cov_pcr_free.20140203.bam.bai",
			sample=thousand_list),
		expand(
			"xyalign_analyses/chrom_stats/plots/{dataset}_{type}.pdf",
			dataset=["thousand", "seq_comp"], type=["count", "depth", "mapq"]),
		expand(
			"xyalign_analyses/hg19/plots/HG00513_wgs_chrX_{type}_BeforeAfterScatter.pdf",
			type=["depth", "MAPQ"]),
		expand(
			"xyalign_analyses/hg19/vcf/{sample}_noprocessing_intersect_postprocessing.vcf",
			sample=human_list),
		expand(
			"xyalign_analyses/hg19/vcf/{sample}_{direction}.{status}_status.txt",
			sample=human_list,
			direction=[
				"postprocessing_minus_noprocessing",
				"noprocessing_minus_postprocessing"],
			status=["gene", "missing"]),
		expand(
			"xyalign_analyses/hg19/vcf/{sample}_{direction}.region_variant_counts.bed",
			sample=human_list,
			direction=[
				"postprocessing_minus_noprocessing",
				"noprocessing_minus_postprocessing"]),
		"xyalign_analyses/hg19/vcf/hg19_chry_readbalance_stats_per_region.txt"

rule prepare_reference_hg19:
	input:
		hg19_ref_path
	output:
		fai = hg19_ref_path + ".fai",
		amb = hg19_ref_path + ".amb",
		dict = hg19_ref_prefix + ".dict"
	params:
		samtools = samtools_path,
		bwa = bwa_path
	run:
		# faidx
		shell("{params.samtools} faidx {input}")
		# .dict
		shell("{params.samtools} dict -o {output.dict} {input}")
		# bwa
		shell("{params.bwa} index {input}")

rule prepare_reference_thousand_genomes:
	input:
		thousand_genomes_ref_path
	output:
		fai = thousand_genomes_ref_path + ".fai",
		dict = thousand_genomes_ref_prefix + ".dict"
	params:
		samtools = samtools_path
	run:
		# faidx
		shell("{params.samtools} faidx {input}")
		# .dict
		shell("{params.samtools} dict -o {output.dict} {input}")

rule map_and_process_reads_hg19_paired_human:
	input:
		fq1 = lambda wildcards: human_fastq_directory + config["human_paired_fastqs"][wildcards.sample][0],
		fq2 = lambda wildcards: human_fastq_directory + config["human_paired_fastqs"][wildcards.sample][1],
		fai = hg19_ref_path + ".fai",
		amb = hg19_ref_path + ".amb",
		ref = hg19_ref_path
	output:
		"processed_bams/{sample}.hg19.mkdup.sorted.bam"
	params:
		id = lambda wildcards: config[wildcards.sample]["ID"],
		sm = lambda wildcards: config[wildcards.sample]["SM"],
		lb = lambda wildcards: config[wildcards.sample]["LB"],
		pu = lambda wildcards: config[wildcards.sample]["PU"],
		pl = lambda wildcards: config[wildcards.sample]["PL"],
		bwa = bwa_path,
		samblaster = samblaster_path,
		samtools = samtools_path,
		threads = 4
	threads: 4
	shell:
		" {params.bwa} mem -t {params.threads} -R "
		"'@RG\\tID:{params.id}\\tSM:{params.sm}\\tLB:{params.lb}\\tPU:{params.pu}\\tPL:{params.pl}' "
		"{input.ref} {input.fq1} {input.fq2} "
		"| {params.samblaster} | {params.samtools} fixmate -O bam - - | {params.samtools} sort "
		"-O bam -o {output}"

rule index_bam_hg19_paired:
	input:
		"processed_bams/{sample}.hg19.mkdup.sorted.bam"
	output:
		"processed_bams/{sample}.hg19.mkdup.sorted.bam.bai"
	params:
		samtools = samtools_path
	shell:
		"{params.samtools} index {input}"

rule index_bam_1000genomes:
	input:
		thousand_genomes_bam_directory + "{sample}.high_cov_pcr_free.20140203.bam"
	output:
		thousand_genomes_bam_directory + "{sample}.high_cov_pcr_free.20140203.bam.bai"
	params:
		samtools = samtools_path
	shell:
		"{params.samtools} index {input}"

rule merge_lcov_HG00512:
	input:
		run1 = "processed_bams/HG00512_lowcov_run1.hg19.mkdup.sorted.bam",
		run1_idx = "processed_bams/HG00512_lowcov_run1.hg19.mkdup.sorted.bam.bai",
		run2 = "processed_bams/HG00512_lowcov_run2.hg19.mkdup.sorted.bam",
		run2_idx = "processed_bams/HG00512_lowcov_run2.hg19.mkdup.sorted.bam.bai"
	output:
		bam = "processed_bams/HG00512_lowcov.hg19.mkdup.sorted.bam",
		bai = "processed_bams/HG00512_lowcov.hg19.mkdup.sorted.bam.bai"
	threads: 4
	params:
		samtools = samtools_path
	run:
		shell("{params.samtools} merge {output.bam} {input.run1} {input.run2}")
		shell("{params.samtools} index {output.bam}")

rule merge_lcov_HG00513:
	input:
		run1 = "processed_bams/HG00513_lowcov_run1.hg19.mkdup.sorted.bam",
		run1_idx = "processed_bams/HG00513_lowcov_run1.hg19.mkdup.sorted.bam.bai",
		run2 = "processed_bams/HG00513_lowcov_run2.hg19.mkdup.sorted.bam",
		run2_idx = "processed_bams/HG00513_lowcov_run2.hg19.mkdup.sorted.bam.bai",
		run3 = "processed_bams/HG00513_lowcov_run3.hg19.mkdup.sorted.bam",
		run3_idx = "processed_bams/HG00513_lowcov_run3.hg19.mkdup.sorted.bam.bai"
	output:
		bam = "processed_bams/HG00513_lowcov.hg19.mkdup.sorted.bam",
		bai = "processed_bams/HG00513_lowcov.hg19.mkdup.sorted.bam.bai"
	params:
		samtools = samtools_path
	threads: 4
	run:
		shell(
			"{params.samtools} merge {output.bam} {input.run1} "
			"{input.run2} {input.run3}")
		shell(
			"{params.samtools} index {output.bam}")

rule merge_wgs_HG00512:
	input:
		run1 = "processed_bams/HG00512_wgs_run1.hg19.mkdup.sorted.bam",
		run1_idx = "processed_bams/HG00512_wgs_run1.hg19.mkdup.sorted.bam.bai",
		run2 = "processed_bams/HG00512_wgs_run2.hg19.mkdup.sorted.bam",
		run2_idx = "processed_bams/HG00512_wgs_run2.hg19.mkdup.sorted.bam.bai",
		run3 = "processed_bams/HG00512_wgs_run3.hg19.mkdup.sorted.bam",
		run3_idx = "processed_bams/HG00512_wgs_run3.hg19.mkdup.sorted.bam.bai",
		run4 = "processed_bams/HG00512_wgs_run4.hg19.mkdup.sorted.bam",
		run4_idx = "processed_bams/HG00512_wgs_run4.hg19.mkdup.sorted.bam.bai",
		run5 = "processed_bams/HG00512_wgs_run5.hg19.mkdup.sorted.bam",
		run5_idx = "processed_bams/HG00512_wgs_run5.hg19.mkdup.sorted.bam.bai"
	output:
		bam = "processed_bams/HG00512_wgs.hg19.mkdup.sorted.bam",
		bai = "processed_bams/HG00512_wgs.hg19.mkdup.sorted.bam.bai"
	params:
		samtools = samtools_path
	threads: 4
	run:
		shell(
			"{params.samtools} merge {output.bam} {input.run1} {input.run2} "
			"{input.run3} {input.run4} {input.run5}")
		shell(
			"{params.samtools} index {output.bam}")

rule merge_wgs_HG00513:
	input:
		run1 = "processed_bams/HG00513_wgs_run1.hg19.mkdup.sorted.bam",
		run1_idx = "processed_bams/HG00513_wgs_run1.hg19.mkdup.sorted.bam.bai",
		run2 = "processed_bams/HG00513_wgs_run2.hg19.mkdup.sorted.bam",
		run2_idx = "processed_bams/HG00513_wgs_run2.hg19.mkdup.sorted.bam.bai",
		run3 = "processed_bams/HG00513_wgs_run3.hg19.mkdup.sorted.bam",
		run3_idx = "processed_bams/HG00513_wgs_run3.hg19.mkdup.sorted.bam.bai",
		run4 = "processed_bams/HG00513_wgs_run4.hg19.mkdup.sorted.bam",
		run4_idx = "processed_bams/HG00513_wgs_run4.hg19.mkdup.sorted.bam.bai",
		run5 = "processed_bams/HG00513_wgs_run5.hg19.mkdup.sorted.bam",
		run5_idx = "processed_bams/HG00513_wgs_run5.hg19.mkdup.sorted.bam.bai",
		run6 = "processed_bams/HG00513_wgs_run6.hg19.mkdup.sorted.bam",
		run6_idx = "processed_bams/HG00513_wgs_run6.hg19.mkdup.sorted.bam.bai"
	output:
		bam = "processed_bams/HG00513_wgs.hg19.mkdup.sorted.bam",
		bai = "processed_bams/HG00513_wgs.hg19.mkdup.sorted.bam.bai"
	params:
		samtools = samtools_path
	threads: 4
	run:
		shell(
			"{params.samtools} merge {output.bam} {input.run1} {input.run2} "
			"{input.run3} {input.run4} {input.run5} {input.run6}")
		shell(
			"{params.samtools} index {output.bam}")

rule xyalign_prepare_hg19_reference:
	input:
		ref = hg19_ref_path,
		fai = hg19_ref_path + ".fai"
	output:
		xx = "xyalign_analyses/hg19/reference/hg19.XXonly.fasta",
		xy = "xyalign_analyses/hg19/reference/hg19.XY.fasta"
	params:
		conda_env = xyalign_anaconda_env,
		xyalign = xyalign_path,
		output_dir = "xyalign_analyses/hg19/",
		ref_mask = hg19_reference_mask_path
	threads:
		4
	shell:
		"source activate {params.conda_env} "
		"&& {params.xyalign} --PREPARE_REFERENCE --ref {input.ref} "
		"--xx_ref_out_name hg19.XXonly.fasta --xy_ref_out_name hg19.XY.fasta "
		"--output_dir {params.output_dir} --x_chromosome chrX "
		"--y_chromosome chrY --bwa_index True --reference_mask {params.ref_mask}"

rule xyalign_hg19_analysis_human:
	input:
		bam = "processed_bams/{sample}.hg19.mkdup.sorted.bam",
		idx = "processed_bams/{sample}.hg19.mkdup.sorted.bam.bai",
		ref = hg19_ref_path,
		xx_in = "xyalign_analyses/hg19/reference/hg19.XXonly.fasta",
		xy_in = "xyalign_analyses/hg19/reference/hg19.XY.fasta"
	output:
		log = "xyalign_analyses/hg19/logfiles/{sample}_hg19_xyalign.log",
		before = "xyalign_analyses/hg19/bed/{sample}_hg19_full_dataframe_depth_mapq_preprocessing.csv",
		after = "xyalign_analyses/hg19/bed/{sample}_hg19_full_dataframe_depth_mapq_postprocessing.csv",
		vcf_before = "xyalign_analyses/hg19/vcf/{sample}_hg19.noprocessing.vcf.gz",
		vcf_after = "xyalign_analyses/hg19/vcf/{sample}_hg19.postprocessing.vcf.gz",
	params:
		xyalign = xyalign_path,
		sample_id = "{sample}_hg19",
		hg19_ref_mask = hg19_reference_mask_path,
		conda_env = xyalign_anaconda_env,
		threads = 4
	threads:
		4
	shell:
		"source activate {params.conda_env} "
		"&& {params.xyalign} --ref {input.ref} --bam {input.bam} "
		"--output_dir xyalign_analyses/hg19 --sample_id {params.sample_id} "
		"--cpus {params.threads} --reference_mask {params.hg19_ref_mask} "
		"--window_size 5000 --chromosomes chr19 chrX chrY --x_chromosome chrX "
		"--y_chromosome chrY --xmx 4g --fastq_compression 4 "
		"--min_depth_filter 0.2 --max_depth_filter 2 --xx_ref_in {input.xx_in} "
		"--xy_ref_in {input.xy_in}"

rule xyalign_1000genomes_analysis:
	input:
		bam = thousand_genomes_bam_directory + "{sample}.high_cov_pcr_free.20140203.bam",
		idx = thousand_genomes_bam_directory + "{sample}.high_cov_pcr_free.20140203.bam.bai",
		ref = thousand_genomes_ref_path
	output:
		"xyalign_analyses/thousand_genomes/logfiles/{sample}_1000genomes_xyalign.log"
	params:
		xyalign = xyalign_path,
		sample_id = "{sample}_1000genomes",
		conda_env = xyalign_anaconda_env,
		threads = 4
	threads:
		4
	shell:
		"source activate {params.conda_env} "
		"&& {params.xyalign} --ref {input.ref} --bam {input.bam} "
		"--output_dir xyalign_analyses/thousand_genomes "
		"--sample_id {params.sample_id} --cpus {params.threads} "
		"--window_size 5000 --chromosomes 19 X Y --x_chromosome X "
		"--y_chromosome Y --CHARACTERIZE_SEX_CHROMS"

rule chrom_stats_hg19_human:
	input:
		bams = expand(
			"processed_bams/{sample}.hg19.mkdup.sorted.bam",
			sample=human_list),
		bais = expand(
			"processed_bams/{sample}.hg19.mkdup.sorted.bam.bai",
			sample=human_list)
	output:
		mapqs = "xyalign_analyses/chrom_stats/results/hg19_human_chrom_stats_mapq.txt",
		depth = "xyalign_analyses/chrom_stats/results/hg19_human_chrom_stats_depth.txt"
	params:
		xyalign = xyalign_path,
		sample_id = "hg19_human",
		conda_env = xyalign_anaconda_env,
		logfile = "hg19_human_chrom_stats.logfile"
	shell:
		"source activate {params.conda_env} "
		"&& {params.xyalign} --CHROM_STATS "
		"--chromosomes chr1 chr8 chr19 chrX chrY chrM --bam {input.bams} "
		"--ref null --sample_id {params.sample_id} --output_dir xyalign_analyses/chrom_stats"

rule chrom_stats_thousand_genomes:
	input:
		bams = expand(
			thousand_genomes_bam_directory + "{sample}.high_cov_pcr_free.20140203.bam",
			sample=thousand_list),
		bais = expand(
			thousand_genomes_bam_directory + "{sample}.high_cov_pcr_free.20140203.bam.bai",
			sample=thousand_list)
	output:
		mapqs = "xyalign_analyses/chrom_stats/results/thousand_chrom_stats_mapq.txt",
		depth = "xyalign_analyses/chrom_stats/results/thousand_chrom_stats_depth.txt"
	params:
		xyalign = xyalign_path,
		sample_id = "thousand",
		conda_env = xyalign_anaconda_env,
		logfile = "thousand_chrom_stats.logfile"
	shell:
		"source activate {params.conda_env} "
		"&& {params.xyalign} --CHROM_STATS --chromosomes 1 8 19 X Y MT "
		"--bam {input.bams} --ref null --sample_id {params.sample_id} "
		"--output_dir xyalign_analyses/chrom_stats"

rule chrom_stats_hg19_human_counts:
	input:
		bams = expand(
			"processed_bams/{sample}.hg19.mkdup.sorted.bam",
			sample=human_list),
		bais = expand(
			"processed_bams/{sample}.hg19.mkdup.sorted.bam.bai",
			sample=human_list)
	output:
		counts = "xyalign_analyses/chrom_stats/results/hg19_human_chrom_stats_count.txt"
	params:
		xyalign = xyalign_path,
		sample_id = "hg19_human",
		conda_env = xyalign_anaconda_env,
		logfile = "hg19_human_chrom_stats_counts.logfile"
	shell:
		"source activate {params.conda_env} "
		"&& {params.xyalign} --CHROM_STATS --use_counts "
		"--chromosomes chr1 chr8 chr19 chrX chrY chrM --bam {input.bams} "
		"--ref null --sample_id {params.sample_id} --output_dir xyalign_analyses/chrom_stats"

rule chrom_stats_thousand_genomes_counts:
	input:
		bams = expand(
			thousand_genomes_bam_directory + "{sample}.high_cov_pcr_free.20140203.bam",
			sample=thousand_list),
		bais = expand(
			thousand_genomes_bam_directory + "{sample}.high_cov_pcr_free.20140203.bam.bai",
			sample=thousand_list)
	output:
		counts = "xyalign_analyses/chrom_stats/results/thousand_chrom_stats_count.txt"
	params:
		xyalign = xyalign_path,
		sample_id = "thousand",
		conda_env = xyalign_anaconda_env,
		logfile = "thousand_chrom_stats_counts.logfile"
	shell:
		"source activate {params.conda_env} "
		"&& {params.xyalign} --CHROM_STATS --use_counts "
		"--chromosomes 1 8 19 X Y MT --bam {input.bams} --ref null "
		"--sample_id {params.sample_id} --output_dir xyalign_analyses/chrom_stats"

rule chrom_stats_plots_hg19:
	input:
		"xyalign_analyses/chrom_stats/results/hg19_human_chrom_stats_{type}.txt"
	output:
		"xyalign_analyses/chrom_stats/plots/seq_comp_{type}.pdf"
	params:
		plot_count_stats = plot_count_stats_path,
		conda_env = xyalign_anaconda_env
	shell:
		"source activate {params.conda_env} && "
		"{params.plot_count_stats} --input {input} "
		"--meta misc/seq_comparison_metadata.txt "
		"--output_prefix xyalign_analyses/chrom_stats/plots/seq_comp_{wildcards.type} "
		"--exclude_suffix '.hg19.mkdup.sorted.bam' --first_chr chrX "
		"--second_chr chrY --const_chr chr19 "
		"--var1_marker color --var1_marker_vals darkslateblue thistle "
		"--var2_marker shape --var2_marker_vals o s v --marker_size 1700 "
		"--legend_marker_scale 0.4"

rule chrom_stats_plots_thousand:
	input:
		"xyalign_analyses/chrom_stats/results/thousand_chrom_stats_{type}.txt"
	output:
		"xyalign_analyses/chrom_stats/plots/thousand_{type}.pdf"
	params:
		plot_count_stats = plot_count_stats_path,
		conda_env = xyalign_anaconda_env
	shell:
		"source activate {params.conda_env} && "
		"{params.plot_count_stats} --input {input} "
		"--meta misc/1000genomes_metadata.txt "
		"--output_prefix xyalign_analyses/chrom_stats/plots/thousand_{wildcards.type} "
		"--exclude_suffix '.high_cov_pcr_free.20140203.bam' --first_chr X "
		"--second_chr Y --const_chr 19 "
		"--var1_marker color --var1_marker_vals darkslateblue thistle "
		"--marker_size 1700 --legend_marker_scale 0.4 --marker_alpha 0.5 "
		"--x_title 'chrX / chr19 ratio' --y_title 'chrY / chr19 ratio'"

rule chrx_before_after_plots:
	input:
		before = "xyalign_analyses/hg19/bed/HG00513_wgs_hg19_full_dataframe_depth_mapq_preprocessing.csv",
		after = "xyalign_analyses/hg19/bed/HG00513_wgs_hg19_full_dataframe_depth_mapq_postprocessing.csv"
	output:
		depth = "xyalign_analyses/hg19/plots/HG00513_wgs_chrX_depth_BeforeAfterScatter.pdf",
		mapq = "xyalign_analyses/hg19/plots/HG00513_wgs_chrX_MAPQ_BeforeAfterScatter.pdf"
	params:
		plot_window_differences = plot_window_differences_path,
		conda_env = xyalign_anaconda_env
	shell:
		"source activate {params.conda_env} && "
		"{params.plot_window_differences} "
		"--before {input.before} --after {input.after} --color black "
		"--chrom chrX --sample_id HG00513_wgs "
		"--output_prefix xyalign_analyses/hg19/plots/HG00513_wgs "
		"--x_limit 155270560 --log_transform_depth"

rule filter_hg19_vcf:
	input:
		"xyalign_analyses/hg19/vcf/{sample}_hg19.{processing}.vcf.gz"
	output:
		"xyalign_analyses/hg19/vcf/{sample}_hg19.{processing}.filtered.vcf"
	params:
		bcftools = bcftools_path
	shell:
		"{params.bcftools} filter --include 'INFO/MQ>=30 && %QUAL>=30' "
		"{input} > {output}"

rule bedtools_intersect_vcf_before_and_after_hg19:
	input:
		before = "xyalign_analyses/hg19/vcf/{sample}_hg19.noprocessing.filtered.vcf",
		after = "xyalign_analyses/hg19/vcf/{sample}_hg19.postprocessing.filtered.vcf"
	output:
		"xyalign_analyses/hg19/vcf/{sample}_noprocessing_intersect_postprocessing.vcf"
	params:
		bedtools = bedtools_path
	shell:
		"{params.bedtools} intersect -header -a {input.after} -b {input.before} "
		"> {output}"

rule bedtools_subtract_vcf_before_minus_after_hg19:
	input:
		before = "xyalign_analyses/hg19/vcf/{sample}_hg19.noprocessing.filtered.vcf",
		after = "xyalign_analyses/hg19/vcf/{sample}_hg19.postprocessing.filtered.vcf"
	output:
		"xyalign_analyses/hg19/vcf/{sample}_noprocessing_minus_postprocessing.vcf"
	params:
		bedtools = bedtools_path
	shell:
		"{params.bedtools} subtract -header -a {input.before} -b {input.after} "
		"> {output}"

rule bedtools_subtract_vcf_after_minus_before_hg19:
	input:
		before = "xyalign_analyses/hg19/vcf/{sample}_hg19.noprocessing.filtered.vcf",
		after = "xyalign_analyses/hg19/vcf/{sample}_hg19.postprocessing.filtered.vcf"
	output:
		"xyalign_analyses/hg19/vcf/{sample}_postprocessing_minus_noprocessing.vcf"
	params:
		bedtools = bedtools_path
	shell:
		"{params.bedtools} subtract -header -a {input.after} -b {input.before} "
		"> {output}"

rule bedtools_count_variants_in_x_regions:
	input:
		regions = "misc/hg19_x_regions.bed",
		vcf = "xyalign_analyses/hg19/vcf/{sample}_{direction}.vcf"
	output:
		"xyalign_analyses/hg19/vcf/{sample}_{direction}.region_variant_counts.bed"
	params:
		bedtools_path = "bedtools"
	shell:
		"bedtools intersect -c -a {input.regions} "
		"-b {input.vcf} > {output}"

rule bedtools_intersect_vcf_with_ccds:
	input:
		vcf = "xyalign_analyses/hg19/vcf/{sample}_{direction}.vcf",
		ccds = "misc/hg19_ccds_genes_chrx.bed"
	output:
		"xyalign_analyses/hg19/vcf/{sample}_{direction}.ccds.bed"
	params:
		bedtools_path = "bedtools"
	shell:
		"bedtools intersect -wa -u -a {input.ccds} "
		"-b {input.vcf} > {output}"

rule get_gene_status_for_ccds:
	input:
		bed = "xyalign_analyses/hg19/vcf/{sample}_{direction}.ccds.bed",
		gene_status = "misc/hg19_chrx_gene_status.txt"
	output:
		gene_status = "xyalign_analyses/hg19/vcf/{sample}_{direction}.gene_status.txt",
		missing_status = "xyalign_analyses/hg19/vcf/{sample}_{direction}.missing_status.txt"
	shell:
		"python misc/Get_gene_status.py --bed {input.bed} "
		"--gene_status {input.gene_status} --outfile {output.gene_status} "
		"--missing_ids_outfile {output.missing_status}"

rule intersect_vcf_with_y_regions:
	input:
		vcf = "xyalign_analyses/hg19/vcf/HG00512_wgs_hg19.noprocessing.vcf.gz",
		bed = "misc/hg19_Y_region_bed_files/hg19_chrY_{region}.bed"
	output:
		"xyalign_analyses/hg19/vcf/HG00512_wgs_hg19.noprocessing.{region}.vcf.gz"
	params:
		bedtools = bedtools_path,
		bgzip = bgzip_path
	shell:
		"{params.bedtools} intersect -header -u -a {input.vcf} -b {input.bed} | bgzip > {output}"

rule plot_regional_chy_readbalance:
	input:
		expand(
			"xyalign_analyses/hg19/vcf/HG00512_wgs_hg19.noprocessing.{region}.vcf.gz",
			region=["ampliconic", "heterochromatic", "other", "par", "xdegen", "xtrans"])
	output:
		"xyalign_analyses/hg19/vcf/hg19_chry_readbalance_stats_per_region.txt"
	params:
		path_prefix = "xyalign_analyses/hg19/vcf",
		conda_env = xyalign_anaconda_env
	shell:
		"source activate {params.conda_env} && python scripts/Plot_read_balance_by_chrY_region.py {output} {params.path_prefix}"
